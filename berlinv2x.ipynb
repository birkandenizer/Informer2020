{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/fraunhoferhhi/BerlinV2X\n",
    "sidelink='/home/bde/Data/BerlinV2X/sidelink_dataframe.parquet'\n",
    "cellular='/home/bde/Data/BerlinV2X/cellular_dataframe.parquet'\n",
    "df = pd.read_parquet(cellular)\n",
    "df.info(verbose=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['measured_qos'].unique()\n",
    "df_datarate = df[df['measured_qos'] == 'datarate']\n",
    "#df_datarate.info(verbose=True)\n",
    "df_delay = df[df['measured_qos'] == 'delay']\n",
    "#df_delay.info(verbose=True)\n",
    "df_delay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downlink = df[df['direction'] == 'downlink']\n",
    "#df_downlink.info(verbose=True)\n",
    "df_uplink = df[df['direction'] == 'uplink']\n",
    "#df_uplink.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pc1 = df[df['device'] == 'pc1']\n",
    "df_pc2 = df[df['device'] == 'pc2']\n",
    "df_pc3 = df[df['device'] == 'pc3']\n",
    "df_pc4 = df[df['device'] == 'pc4']\n",
    "#df_pc?.info()\n",
    "selected_df = df_pc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['device', 'ping_ms'])\n",
    "df_new = selected_df[['datarate', 'PCell_RSRP_1','PCell_RSRP_2','PCell_RSRQ_1','PCell_RSRQ_2','PCell_RSSI_1','PCell_RSSI_2','PCell_SNR_1','PCell_SNR_2', 'operator']]\n",
    "#df_new = selected_df[['datarate', 'PCell_RSRP_1','PCell_RSRP_2','PCell_RSRQ_1','PCell_RSRQ_2','PCell_RSSI_1','PCell_RSSI_2','PCell_SNR_1','PCell_SNR_2', 'operator',\n",
    "#                      'SCell_RSRP_1','SCell_RSRP_2','SCell_RSRQ_1','SCell_RSRQ_2','SCell_RSSI_1','SCell_RSSI_2','SCell_SNR_1']]\n",
    "\n",
    "#df_new = selected_df[['datarate', 'SCell_RSRP_1','SCell_RSRP_2','SCell_RSRQ_1','SCell_RSRQ_2','SCell_RSSI_1','SCell_RSSI_2','SCell_SNR_1', 'operator']]\n",
    "\n",
    "df_new = df_new.dropna()\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.head(100)\n",
    "df_new.to_csv(f'data/BERLINV2X/test.csv', encoding='utf-8', index=False)\n",
    "#df_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['datetime'] = df_new.index\n",
    "\n",
    "groups=(df_new['datetime'].diff()>pd.Timedelta(seconds=1)).cumsum()+1\n",
    "max_len = 0\n",
    "continous_groups = []\n",
    "for i , group in df_new.groupby(groups):\n",
    "    if len(group) > 2048:\n",
    "        max_len = len(group)\n",
    "        continous_groups.append(group)\n",
    "        print(len(group))\n",
    "for group in continous_groups:\n",
    "    group.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest = continous_groups[0]\n",
    "# 0, 3, 4, 5, 9, 10, 11, 12, 13\n",
    "\"\"\" longest = pd.concat([continous_groups[0],\n",
    "                    continous_groups[3],\n",
    "                    continous_groups[4],\n",
    "                    continous_groups[5],\n",
    "                    continous_groups[9],\n",
    "                    continous_groups[10],\n",
    "                    continous_groups[11],\n",
    "                    continous_groups[12],\n",
    "                    continous_groups[13]]) \"\"\"\n",
    "longest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest['date'] = longest['datetime']\n",
    "longest = longest.drop(columns=['operator', 'datetime'])\n",
    "longest.to_csv(f'data/BERLINV2X/longest.csv', encoding='utf-8', index=False)\n",
    "longest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 3, 4, 5, 9, 10, 11, 12, 13\n",
    "SCOPE = 13\n",
    "continous_groups[SCOPE][['datarate']].plot(figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.query('\"2014-07-23 07:55:00\" <= datetime <= \"2014-07-23 08:20:00\"')\n",
    "continous_groups[SCOPE][['PCell_RSRP_1', 'PCell_RSRQ_1', 'PCell_RSSI_1', 'PCell_SNR_1']].plot(figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(20, 6))\n",
    "\n",
    "sns.heatmap(longest.corr('pearson'), ax=ax[0], annot=True)\n",
    "sns.heatmap(longest.corr('spearman'), ax=ax[1], annot=True)\n",
    "sns.heatmap(longest.corr('kendall'), ax=ax[2], annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_corr(dataframe, feature):\n",
    "    fig, ax = plt.subplots(1,3, figsize=(20, 6))\n",
    "\n",
    "    # when the Pearson and Spearman values are not much different, \n",
    "    # our data tends to not have extreme values (outliers)\n",
    "    corr1 = dataframe.corr('pearson')[[feature]].sort_values(by=feature, ascending=False)\n",
    "    corr2 = dataframe.corr('spearman')[[feature]].sort_values(by=feature, ascending=False)\n",
    "    #ordinal correlation (Spearman & Kendall Tau)\n",
    "    corr3 = dataframe.corr('kendall')[[feature]].sort_values(by=feature, ascending=False)\n",
    "    \n",
    "    s1 = sns.heatmap(corr1, ax=ax[0], annot=True)\n",
    "    #s1.set(xlabel='X-Axis', ylabel='Y-Axis')\n",
    "    s1.set(xlabel='Pearson')\n",
    "    s2 = sns.heatmap(corr2, ax=ax[1], annot=True)\n",
    "    s2.set(xlabel='Spearman')\n",
    "    s3 = sns.heatmap(corr3, ax=ax[2], annot=True)\n",
    "    s3.set(xlabel='Kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 3, 4, 5, 9, 10, 11, 12, 13\n",
    "multi_corr(continous_groups[0], 'datarate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "informer",
   "language": "python",
   "name": "informer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
