{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/fraunhoferhhi/BerlinV2X\n",
    "sidelink='/home/bde/Data/BerlinV2X/sidelink_dataframe.parquet'\n",
    "cellular='/home/bde/Data/BerlinV2X/cellular_dataframe.parquet'\n",
    "df = pd.read_parquet(cellular)\n",
    "#df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTION_downlink = True\n",
    "# \"direction == 'downlink'\n",
    "# \"direction == 'uplink'\n",
    "# measured_qos == 'datarate'\n",
    "# measured_qos == 'delay'\n",
    "# Filter only for downlink datarate measurements\n",
    "filtered_data = df.query(\"direction == 'downlink' & measured_qos == 'datarate'\")\n",
    "\n",
    "# Remove incomplete measurements without datarate\n",
    "filtered_data = filtered_data.dropna(subset='datarate')\n",
    "\n",
    "# Train and test split along operators\n",
    "operator_1 = filtered_data.query(\"operator == 1\")\n",
    "operator_1_pc_1 = operator_1.query(\"device == 'pc1'\")\n",
    "operator_1_pc_2 = operator_1.query(\"device == 'pc2'\")\n",
    "operator_1_pc_3 = operator_1.query(\"device == 'pc3'\")\n",
    "operator_1_pc_4 = operator_1.query(\"device == 'pc4'\")\n",
    "\n",
    "print(len(operator_1_pc_1))\n",
    "print(len(operator_1_pc_2))\n",
    "print(len(operator_1_pc_3))\n",
    "print(len(operator_1_pc_4))\n",
    "\n",
    "operator_2 = filtered_data.query(\"operator == 2\")\n",
    "operator_2_pc_1 = operator_2.query(\"device == 'pc1'\")\n",
    "operator_2_pc_2 = operator_2.query(\"device == 'pc2'\")\n",
    "operator_2_pc_3 = operator_2.query(\"device == 'pc3'\")\n",
    "operator_2_pc_4 = operator_2.query(\"device == 'pc4'\")\n",
    "\n",
    "print(len(operator_2_pc_1))\n",
    "print(len(operator_2_pc_2))\n",
    "print(len(operator_2_pc_3))\n",
    "print(len(operator_2_pc_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = operator_2_pc_3[['datarate', 'PCell_RSRP_1','PCell_RSRP_2','PCell_RSRQ_1','PCell_RSRQ_2','PCell_RSSI_1','PCell_RSSI_2','PCell_SNR_1','PCell_SNR_2']]\n",
    "#df_new = operator_2_pc_2[['datarate', 'SCell_RSRP_1','SCell_RSRP_2','SCell_RSRQ_1','SCell_RSRQ_2','SCell_RSSI_1','SCell_RSSI_2','SCell_SNR_1','SCell_SNR_2']]\n",
    "df_new = df_new.dropna()\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[['datarate']].plot(figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['datetime'] = df_new.index\n",
    "\n",
    "groups=(df_new['datetime'].diff()>pd.Timedelta(seconds=1)).cumsum()+1\n",
    "max_len = 0\n",
    "continous_groups = []\n",
    "for i , group in df_new.groupby(groups):\n",
    "    if len(group) > 512:\n",
    "        max_len = len(group)\n",
    "        continous_groups.append(group)\n",
    "        print(len(group))\n",
    "#for group in continous_groups:\n",
    "    #group.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPE = 0\n",
    "continous_groups[SCOPE][['datarate']].plot(figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_groups[SCOPE][['PCell_RSRP_1', 'PCell_RSRQ_1', 'PCell_RSSI_1', 'PCell_SNR_1']].plot(figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_groups[SCOPE][['PCell_RSRP_2', 'PCell_RSRQ_2', 'PCell_RSSI_2', 'PCell_SNR_2']].plot(figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df = continous_groups[SCOPE]\n",
    "df['date'] = df['datetime']\n",
    "df = df.drop(columns=['operator', 'datetime'])\n",
    "df.to_parquet(f'data/BERLINV2X/continous_groups__{SCOPE}.parquet.gzip',compression='gzip')\n",
    "df.to_csv(f'data/BERLINV2X/continous_groups_{SCOPE}.csv', encoding='utf-8', index=False)\n",
    "df.head() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest = pd.concat(continous_groups)\n",
    "longest['date'] = longest['datetime']\n",
    "longest = longest.drop(columns=['datetime'])\n",
    "longest.to_parquet(f'data/BERLINV2X/consecutive_512_operator_2_pc_3.parquet.gzip',compression='gzip')\n",
    "longest.to_csv(f'data/BERLINV2X/consecutive_512_operator_2_pc_3.csv', encoding='utf-8', index=False)\n",
    "longest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" qos_column = 'datarate'\n",
    "\n",
    "downlink_columns = [\n",
    "     'ping_ms',\n",
    "     'datarate',\n",
    "     'PCell_RSRP_max',\n",
    "     'PCell_RSRQ_max',\n",
    "     'PCell_RSSI_max',\n",
    "     'PCell_SNR_1',\n",
    "     'PCell_SNR_2',\n",
    "     'PCell_Downlink_Num_RBs',\n",
    "     'PCell_Downlink_TB_Size',\n",
    "     'PCell_Downlink_Average_MCS',\n",
    "     'PCell_Downlink_frequency',\n",
    "     'PCell_Downlink_bandwidth_MHz',\n",
    "     'PCell_Cell_Identity',\n",
    "     'PCell_freq_MHz',\n",
    "     'SCell_RSRP_max',\n",
    "     'SCell_RSRQ_max',\n",
    "     'SCell_RSSI_max',\n",
    "     'SCell_SNR_1',\n",
    "     'SCell_SNR_2',\n",
    "     'SCell_Downlink_Num_RBs',\n",
    "     'SCell_Downlink_TB_Size',\n",
    "     'SCell_Downlink_Average_MCS',\n",
    "     'SCell_Downlink_frequency',\n",
    "     'SCell_Downlink_bandwidth_MHz',\n",
    "     'SCell_Cell_Identity',\n",
    "     'SCell_freq_MHz',\n",
    "     'Latitude',\n",
    "     'Longitude',\n",
    "     'Altitude',\n",
    "     'speed_kmh',\n",
    "     'COG',\n",
    "     'precipIntensity',\n",
    "     'precipProbability',\n",
    "     'temperature',\n",
    "     'apparentTemperature',\n",
    "     'dewPoint',\n",
    "     'humidity',\n",
    "     'pressure',\n",
    "     'windSpeed',\n",
    "     'cloudCover',\n",
    "     'uvIndex',\n",
    "     'visibility',\n",
    "     'Traffic Jam Factor']\n",
    "\n",
    "uplink_columns = [\n",
    "     'ping_ms',\n",
    "     'datarate',\n",
    "     'PCell_RSRP_max',\n",
    "     'PCell_RSRQ_max',\n",
    "     'PCell_RSSI_max',\n",
    "     'PCell_SNR_1',\n",
    "     'PCell_SNR_2',\n",
    "     'PCell_Uplink_Num_RBs',\n",
    "     'PCell_Uplink_TB_Size',\n",
    "     'PCell_Uplink_Tx_Power_(dBm)',\n",
    "     'PCell_Uplink_frequency',\n",
    "     'PCell_Uplink_bandwidth_MHz',\n",
    "     'PCell_Cell_Identity',\n",
    "     'PCell_freq_MHz',\n",
    "     'Latitude',\n",
    "     'Longitude',\n",
    "     'Altitude',\n",
    "     'speed_kmh',\n",
    "     'COG',\n",
    "     'precipIntensity',\n",
    "     'precipProbability',\n",
    "     'temperature',\n",
    "     'apparentTemperature',\n",
    "     'dewPoint',\n",
    "     'humidity',\n",
    "     'pressure',\n",
    "     'windSpeed',\n",
    "     'cloudCover',\n",
    "     'uvIndex',\n",
    "     'visibility',\n",
    "     'Traffic Jam Factor']\n",
    "\n",
    "print(f\"The BERLINV2X uses {len(downlink_columns)} download features and {len(uplink_columns)} upload features\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" if DIRECTION_downlink:\n",
    "    # Missing value imputation\n",
    "    d_1 = train_data_1[downlink_columns].fillna(0)\n",
    "    d_2 = train_data_4[downlink_columns].fillna(0)\n",
    "    d_3 = test_data_2[downlink_columns].fillna(0)\n",
    "    d_4 = test_data_3[downlink_columns].fillna(0)\n",
    "\n",
    "    downlink = pd.concat([d_1, d_2, d_3, d_4])\n",
    "    downlink['date'] = downlink.index.tz_localize(None)\n",
    "    downlink['PCell_Downlink_bandwidth_MHz'] = pd.to_numeric(downlink['PCell_Downlink_bandwidth_MHz'])\n",
    "    downlink['SCell_Downlink_bandwidth_MHz'] = pd.to_numeric(downlink['SCell_Downlink_bandwidth_MHz'])\n",
    "    downlink.to_csv(f'data/BERLINV2X/berlin-downlink-delay.csv', encoding='utf-8', index=False)\n",
    "    downlink.info()\n",
    "    downlink.head()\n",
    "    df = downlink \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" if not DIRECTION_downlink:\n",
    "    u_1 = train_data_1[uplink_columns].fillna(0)\n",
    "    u_2 = train_data_4[uplink_columns].fillna(0)\n",
    "    u_3 = test_data_2[uplink_columns].fillna(0)\n",
    "    u_4 = test_data_3[uplink_columns].fillna(0)\n",
    "\n",
    "    uplink = pd.concat([u_1, u_2, u_3, u_4])\n",
    "    uplink['date'] = uplink.index.tz_localize(None)\n",
    "    uplink['PCell_Uplink_bandwidth_MHz'] = pd.to_numeric(uplink['PCell_Uplink_bandwidth_MHz'])\n",
    "    #uplink['SCell_Uplink_bandwidth_MHz'] = pd.to_numeric(uplink['SCell_Uplink_bandwidth_MHz'])\n",
    "    uplink.to_csv(f'data/BERLINV2X/berlin-uplink-delay.csv', encoding='utf-8', index=False)\n",
    "    uplink.info()\n",
    "    uplink.head()\n",
    "    df = uplink \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df.head() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots(1,3, figsize=(20, 6))\n",
    "#sns.heatmap(df.corr('pearson'), ax=ax[0], annot=True)\n",
    "#sns.heatmap(df.corr('spearman'), ax=ax[1], annot=True)\n",
    "#sns.heatmap(df.corr('kendall'), ax=ax[2], annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_corr(df, feature):\n",
    "    fig, ax = plt.subplots(1,3, figsize=(20, 6))\n",
    "\n",
    "    # when the Pearson and Spearman values are not much different, \n",
    "    # our data tends to not have extreme values (outliers)\n",
    "    corr1 = df.corr('pearson')[[feature]].sort_values(by=feature, ascending=False)\n",
    "    corr2 = df.corr('spearman')[[feature]].sort_values(by=feature, ascending=False)\n",
    "    corr3 = df.corr('kendall')[[feature]].sort_values(by=feature, ascending=False)\n",
    "    #ordinal correlation (Spearman & Kendall Tau)\n",
    "\n",
    "    sns.heatmap(corr1, ax=ax[0], annot=True)\n",
    "    sns.heatmap(corr2, ax=ax[1], annot=True)\n",
    "    sns.heatmap(corr3, ax=ax[2], annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_corr(longest, 'datarate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi_corr(longest, 'ping_ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "informer",
   "language": "python",
   "name": "informer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
